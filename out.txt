===== camera.py =====
import cv2
import numpy as np
from typing import Optional, Tuple, Any

class Camera:
    def __init__(self):
        self.cap: Optional[cv2.VideoCapture] = None
        self._IDX = 0 # 1 for obs
        # self._CAM_W = 540
        # self._CAM_H = 720
        self._CAM_W = 768
        self._CAM_H = 432

    def initialize(self):
        self.cap = cv2.VideoCapture(self._IDX)
        if self.cap.isOpened():
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self._CAM_W)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self._CAM_H)
            self.is_opened = True

    def read_frame(self) -> Tuple[bool, Optional[np.ndarray], Any]: # type: ignore
        if not self.is_opened or not self.cap:
            return False, None, None
        
        ret, frame = self.cap.read()
        if ret:
            frame = cv2.flip(frame, 1)
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return ret, frame, image # type: ignore
    
    def release(self):
        if self.cap:
            self.cap.release()
        self.is_opened = False

    def putText(self, frame, text, point, font, size, color, thickness):
        cv2.putText(frame, text, point, font, size, color, thickness)
   

===== hands.py =====
from typing import List, Any
import cv2
import numpy as np
import mediapipe as mp

class Hands:
    def __init__(self):
        self.finger_angles: List[Any] = []
        self.LEFT_HAND_COLOR = (255, 0, 0)
        self.RIGHT_HAND_COLOR = (0, 0, 255)
        self.mp_hands = mp.solutions.hands # type: ignore
        self.mp_drawing = mp.solutions.drawing_utils # type: ignore

        self.hands = self.mp_hands.Hands(
            max_num_hands = 2, min_tracking_confidence = 0.5, min_detection_confidence = 0.7
        )

    @property
    def get_finger_angles(self) -> List[Any]:
        return self.finger_angles

    def draw(self, frame, results):
        # Hand Landmarks
        # draw() will draw hand landmarks for both hands

        if results.multi_hand_landmarks:
            for idx, lm in enumerate(results.multi_hand_landmarks):
                landmarks = np.array([[l.x, l.y, l.z] for l in lm.landmark])
                hand_label = results.multi_handedness[idx].classification[0].label
                self._draw2(frame, landmarks, hand_label)
                self.mp_drawing.draw_landmarks(
                    frame, lm, self.mp_hands.HAND_CONNECTIONS,
                    landmark_drawing_spec = self.mp_drawing.DrawingSpec(
                        color = self.LEFT_HAND_COLOR if (hand_label == 'Left') else self.RIGHT_HAND_COLOR,
                        thickness = 2, circle_radius = 2
                    )
                )

    def _draw2(self, frame, landmarks, hand_label=None):
        # _draw2() will draw vectors and angles on individual hands

        h, w, _ = frame.shape
        points = (landmarks[:, :2] * [w, h]).astype(int)

        # Palm Normal Vectors
        palm_normal = self._compute_palm_normal_vector(landmarks, hand_label)
        wrist = points[0]
        end_point = (wrist + (palm_normal[:2] * 100)).astype(int)
        cv2.arrowedLine(frame, wrist, tuple(end_point), (0, 255, 0), 2)

        pitch, yaw = self._palm_orientation_angles(palm_normal)
        cv2.putText(frame, f"Pitch: {pitch:.1f}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        cv2.putText(frame, f"Yaw: {yaw:.1f}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
       
        # Finger Angles
        self.finger_angles = self._compute_finger_angles(landmarks)
        for i, angle in enumerate(self.finger_angles): # type: ignore
            cv2.putText(frame, f"F{i+1}:{angle:.1f}", (10, 90 + i * 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (39, 187, 255), 2)
        

    def _compute_palm_normal_vector(self, landmarks, hand_label=None):
        wrist = landmarks[0]
        index_mcp = landmarks[5]
        pinky_mcp = landmarks[17]
        v1 = index_mcp - wrist
        v2 = pinky_mcp - wrist

        normal = np.cross(v1, v2)

        # cross product order matters for direction, so to account for chirality, when hand_label = 'Left', if-flip ko lang
        if hand_label == 'Left':
            normal = -normal

        return normal / (np.linalg.norm(normal) + 1e-6)

    def _palm_orientation_angles(self, normal):
        pitch = np.arcsin(normal[1])
        yaw = np.arctan2(normal[0], normal[2])
        return np.degrees(pitch), np.degrees(yaw)
    
    def _compute_angle(self, a, b, c):
        ba = a - b
        bc = c - b
        cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)
        return np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))

    def _compute_finger_angles(self, landmarks):
        indices = [
            (1, 2, 3),   # Thumb
            (5, 6, 7),   # Index
            (9, 10, 11), # Middle
            (13, 14, 15),# Ring
            (17, 18, 19) # Pinky
        ]
        return [self._compute_angle(landmarks[a], landmarks[b], landmarks[c]) for a, b, c in indices]

    def extract_all_hand_features(self, results, image_shape):
        frame_vector = []

        if not results.multi_hand_landmarks:
            return np.zeros(146, dtype = np.float32)
        
        hands_data = []
        for idx, lm in enumerate(results.multi_hand_landmarks):
            landmarks = np.array([[l.x, l.y, l.z] for l in lm.landmark])
            label = results.multi_handedness[idx].classification[0].label
            hands_data.append((label, landmarks))

        sorted_hands_data = sorted(hands_data, key = lambda x: x[0]) # hands data always ordered -> Left, Right

        for label, landmarks in sorted_hands_data:
            features = self._extract_hand_features(landmarks, label)
            frame_vector.append(features)

        while len(frame_vector) < 2:
            frame_vector.append(np.zeros_like(frame_vector[0]))

        return np.concatenate(frame_vector)

    def _extract_hand_features(self, landmarks, hand_label):
        flattened_landmark = landmarks.flatten()
        normal = self._compute_palm_normal_vector(landmarks, hand_label)
        pitch, yaw = self._palm_orientation_angles(normal)
        finger_angles = self._compute_finger_angles(landmarks)

        return np.concatenate([
            flattened_landmark,
            normal,
            [pitch, yaw],
            finger_angles
        ])



===== procs.py =====
import os
import logging
import numpy as np
import tkinter as tk
from tkinter import simpledialog
from datetime import datetime

class UIProcess:
    @staticmethod
    def prompt_label() -> str|None:
        root = tk.Tk()
        root.withdraw()
        label: str|None = simpledialog.askstring(title = "Label Input", prompt = "Enter ASL Label:")
        if label is None:
            return None
        root.destroy()
        return label
    
class FileProcs:
    @staticmethod
    def count_dirs():
        folder = os.path.join("data", "landmark_sequences")
        os.makedirs(folder, exist_ok = True)
        print("===== EXISTING LABELS =====")
        f1: list[str] = os.listdir(folder)
        if len(f1) < 1:
            print ("None.")
        else:
            for label in os.listdir(folder):
                print(f"\"{label}\": {len([f for f in os.listdir(os.path.join(folder, label)) if os.path.isfile(os.path.join(folder, label, f))])}")
        print("===== END =====")

    @staticmethod
    def save_sequence(sequence, label):
        folder = os.path.join("data", "landmark_sequences", label)
        os.makedirs(folder, exist_ok = True)
        filename = os.path.join(
            folder, 
            f"{label}_{datetime.now().strftime('%Y%m%d%H%M%S')}.npy"
            )
        np.save(filename, sequence)
        logging.info(f"Saved: {label} => {filename}")
        logging.info(f"Size of {filename}: {os.path.getsize(filename)}")
        logging.info(f"File count for {folder}: {len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))])}")

===== sequence.py =====
import numpy as np

class Sequence:
    def __init__(self):
        self.reset()
        self.sequence_length = 20

    def reset(self):
        self.sequence = []

    def append(self, frame_vector):
        self.sequence.append(frame_vector)
    
    def is_full(self):
        return len(self.sequence) >= self.sequence_length
    
    def get_sequence(self):
        return np.array(self.sequence)


===== __init__.py =====
"""
very important python file, don't delete
"""

===== data_collection.py =====
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

import cv2
import logging
from data_collection_src.camera import Camera
from data_collection_src.hands import Hands
from data_collection_src.sequence import Sequence
from data_collection_src.procs import UIProcess, FileProcs

# 's' to record sequence
# 'q' to quit
# '0' to count files

class Main:
    @staticmethod
    def main():
        collecting = False

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )

        camera = Camera()
        hands = Hands()
        frame_sequence = Sequence()

        camera.initialize()
        FileProcs.count_dirs()

        while True:
            ret, frame, image = camera.read_frame()
            if not ret:
                continue

            results = hands.hands.process(image)

            if collecting:
                frame_features = hands.extract_all_hand_features(results, image.shape)
                frame_sequence.append(frame_features)

                camera.putText(frame, f"Collecting: {len(frame_sequence.sequence)}/{frame_sequence.sequence_length}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (106, 255, 0), 2)

                if frame_sequence.is_full():
                    collecting = False
                    label: str|None = UIProcess.prompt_label()

                    if label == None:
                        logging.info(f"Label null. Sequence not saved.")
                    elif label == "":
                        logging.info(f"Label empty. Sequence not saved.")
                    else:
                        FileProcs.save_sequence(frame_sequence.get_sequence(), label)

            hands.draw(frame, results)
            cv2.imshow("demo", frame) # type: ignore

            # to quit, either shift+q or close window
            # to start collection, shift+s

            key = cv2.waitKey(1) & 0xFF
            if key == ord('s') or key == ord(' '):
                frame_sequence.reset() # reset every before collection
                logging.info("Collecting sequence...")
                collecting = True
            elif key == ord('0'):
                FileProcs.count_dirs()
            elif key == ord('Q') or cv2.getWindowProperty("demo", cv2.WND_PROP_VISIBLE) < 1:
                break

        camera.release()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    Main.main()